{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad17b35-e42a-4e04-a99f-ec850e0141c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_20212\\2719461471.py:3: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4726e908-7a14-4d9d-97d5-f4e9fe558616",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d728b3-c898-4aca-9872-7ef97f3c67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5b3b7c-9ac8-4225-ba39-55c6e12c2882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with image data\\bullet\\.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, image_class)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for image in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image)\n",
    "            try:\n",
    "                img = cv2.imread(image_path)\n",
    "                tip = imghdr.what(image_path)\n",
    "                if tip not in image_exts:\n",
    "                    print('Image not in ext list {}'.format(image_path))\n",
    "                    os.remove(image_path)\n",
    "            except Exception as e:\n",
    "                print('Issue with image {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b68f21-5789-403d-a225-4eb8971ae66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 389 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, image_size=(256, 256), batch_size=32)\n",
    "classes = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4201183b-dde5-42c7-8a9d-b79a9425b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(data.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e31b816-f6d5-4055-b7ba-2e79e230a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x / 255, tf.one_hot(y, num_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eade74f-e69a-410a-b13a-a10de5afe731",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b932ed-45b9-4888-9998-07c606f2bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b00f719-a065-4b83-ad35-0a0374ec90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3697139 (14.10 MB)\n",
      "Trainable params: 3697139 (14.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0788be-027d-45f5-9b29-60358595cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.2) + 1\n",
    "test_size = int(len(data) * 0.1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e45a041-a9bc-4c01-8bc0-d7ff0cebe209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f988a4e-6c43-46cd-a608-0e16f895adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13f2cf9-86d3-4a9a-97b9-95921df01a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2be92f-2925-40e6-8783-130eaab0ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 15s 1s/step - loss: 2.7404 - accuracy: 0.3299 - val_loss: 1.0682 - val_accuracy: 0.4688\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 15s 1s/step - loss: 1.0519 - accuracy: 0.4653 - val_loss: 0.9900 - val_accuracy: 0.5104\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.9484 - accuracy: 0.5972 - val_loss: 1.0146 - val_accuracy: 0.5208\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.9223 - accuracy: 0.5521 - val_loss: 0.9442 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.8924 - accuracy: 0.5833 - val_loss: 0.7555 - val_accuracy: 0.7292\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.7796 - accuracy: 0.6979 - val_loss: 0.5835 - val_accuracy: 0.7917\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6780 - accuracy: 0.7639 - val_loss: 0.5963 - val_accuracy: 0.7812\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.5716 - accuracy: 0.7917 - val_loss: 0.5691 - val_accuracy: 0.7917\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.5032 - accuracy: 0.8021 - val_loss: 0.4364 - val_accuracy: 0.8854\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4286 - accuracy: 0.8507 - val_loss: 0.5109 - val_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3393 - accuracy: 0.9028 - val_loss: 0.2094 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2398 - accuracy: 0.9410 - val_loss: 0.2379 - val_accuracy: 0.9375\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1751 - accuracy: 0.9583 - val_loss: 0.1110 - val_accuracy: 0.9792\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1246 - accuracy: 0.9688 - val_loss: 0.1013 - val_accuracy: 0.9688\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1037 - accuracy: 0.9688 - val_loss: 0.0810 - val_accuracy: 0.9896\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0608 - accuracy: 0.9826 - val_loss: 0.0654 - val_accuracy: 0.9792\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 0.0502 - val_accuracy: 0.9896\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0596 - accuracy: 0.9931 - val_loss: 0.0598 - val_accuracy: 0.9896\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0439 - accuracy: 0.9896 - val_loss: 0.0310 - val_accuracy: 0.9896\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0428 - accuracy: 0.9826 - val_loss: 0.0515 - val_accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0f9031d-ca08-44e0-84e6-9e14da5ca15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Test loss: 0.04390560835599899\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_metrics = model.evaluate(test)\n",
    "print(\"Test loss:\", test_metrics[0])\n",
    "print(\"Test accuracy:\", test_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc766c21-27f7-4fbe-a12f-7b62fb347fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'bullettest.jpg'\n",
    "img = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d40f12-63bc-4fdc-a717-cf3c76e4f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256, 256)) / 255.0\n",
    "resize = tf.expand_dims(resize, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac80247-7a32-4bcc-a774-47c9dd499ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2602d599-c07d-4bfb-9249-c8638b1e0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_index = tf.argmax(predictions, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea7b174a-0bb9-4a95-a200-1cb9254b3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = classes.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb6b8197-2dce-4c2a-b06a-1acf0c9b4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_name = class_names[predicted_class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "231e7cf2-f1e4-4f01-9a58-a29ee8c74898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: bullet\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted class: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a609c7cb-3929-4954-b22b-e0d25850e045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f4fa08-34b7-4d35-9bf1-97d0aff5a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c8619ac-57ca-41d5-b572-7a608b2534d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression (466742034.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model my_model /tjs\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to expression\n"
     ]
    }
   ],
   "source": [
    "tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model my_model /tjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c258ef4-da8d-4e1c-951a-c3f5fe052d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 37, in <module>\n",
      "    from tensorflowjs.converters import tf_saved_model_conversion_v2\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\", line 42, in <module>\n",
      "    import tensorflow_hub as hub\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflow_hub\\__init__.py\", line 90, in <module>\n",
      "    from tensorflow_hub.feature_column import image_embedding_column\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflow_hub\\feature_column.py\", line 20, in <module>\n",
      "    from tensorflow_hub import image_util\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflow_hub\\image_util.py\", line 17, in <module>\n",
      "    from tensorflow_hub import image_module_info_pb2\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\tensorflow_hub\\image_module_info_pb2.py\", line 36, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\google\\protobuf\\descriptor.py\", line 561, in __new__\n",
      "    _message.Message._CheckCalledFromGeneratedFile()\n",
      "TypeError: Descriptors cannot not be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model my_model /path/to/output_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ecd9b7d-0a6f-4c54-8178-fd627353849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Desktop\\SE factory\\Final Project\\medtech\\tensorflow\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b69aca11-8b74-4cf5-ab3c-464a2c852ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cc26e47-0261-4960-9ece-4908ec3539c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression (466742034.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model my_model /tjs\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to expression\n"
     ]
    }
   ],
   "source": [
    "tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model my_model /tjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cee8a-f3e9-42f1-a5c4-6a933e547d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
